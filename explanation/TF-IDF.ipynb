{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e5d574c",
   "metadata": {},
   "source": [
    "# TF-IDF (Term Frequency - Inverse Document Frequency)\n",
    "\n",
    "## Formula\n",
    "\n",
    "$$\\text{TF-IDF}(t, d) = \\text{TF}(t, d) \\times \\text{IDF}(t)$$\n",
    "\n",
    "### Term Frequency (TF)\n",
    "\n",
    "$$\\text{TF}(t, d) = \\frac{\\text{Number of times term } t \\text{ appears in document } d}{\\text{Total number of terms in document } d}$$\n",
    "\n",
    "### Inverse Document Frequency (IDF)\n",
    "\n",
    "$$\\text{IDF}(t) = \\log\\left(\\frac{\\text{Total number of documents}}{\\text{Number of documents containing term } t}\\right)$$\n",
    "\n",
    "## What It Does\n",
    "\n",
    "TF-IDF measures **how important a word is to a document** in a collection of documents:\n",
    "\n",
    "- **High TF-IDF**: Word is frequent in this document but rare in others → Important/Distinctive\n",
    "- **Low TF-IDF**: Word is either rare in this document or common across all documents → Less important\n",
    "\n",
    "Common words like \"the\", \"is\", \"and\" get low scores because they appear everywhere.\n",
    "Specific/unique words get high scores because they're distinctive.\n",
    "\n",
    "## Important Parameters\n",
    "\n",
    "```python\n",
    "TfidfVectorizer(\n",
    "    max_features=None,      # Limit vocabulary size\n",
    "    stop_words='english',   # Remove common words\n",
    "    ngram_range=(1, 1),     # (min_n, max_n) for n-grams\n",
    "    min_df=1,               # Minimum document frequency\n",
    "    max_df=1.0,             # Maximum document frequency\n",
    "    lowercase=True,         # Convert to lowercase\n",
    "    norm='l2',              # Normalization (l2, l1, or None)\n",
    "    use_idf=True,           # Enable IDF weighting\n",
    "    smooth_idf=True,        # Add 1 to avoid zero division\n",
    "    sublinear_tf=False      # Use log scaling for TF\n",
    ")\n",
    "```\n",
    "\n",
    "### Parameter Examples\n",
    "\n",
    "```python\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "documents = [\n",
    "    \"I love machine learning and deep learning\",\n",
    "    \"Machine learning is amazing\",\n",
    "    \"Deep learning uses neural networks\"\n",
    "]\n",
    "\n",
    "# Bigrams (2-word phrases)\n",
    "vectorizer_bigram = TfidfVectorizer(ngram_range=(1, 2))\n",
    "tfidf = vectorizer_bigram.fit_transform(documents)\n",
    "print(\"With bigrams:\", vectorizer_bigram.get_feature_names_out())\n",
    "\n",
    "# Limit vocabulary to top 5 features\n",
    "vectorizer_limited = TfidfVectorizer(max_features=5)\n",
    "tfidf = vectorizer_limited.fit_transform(documents)\n",
    "print(\"\\nTop 5 features:\", vectorizer_limited.get_feature_names_out())\n",
    "\n",
    "# Ignore words that appear in > 50% of documents\n",
    "vectorizer_max_df = TfidfVectorizer(max_df=0.5)\n",
    "tfidf = vectorizer_max_df.fit_transform(documents)\n",
    "print(\"\\nMax df=0.5:\", vectorizer_max_df.get_feature_names_out())\n",
    "```\n",
    "\n",
    "**Each document vector is normalized to length 1 (L2 norm = 1)**\n",
    "\n",
    "## When to Use TF-IDF\n",
    "\n",
    "**Use when:**\n",
    "- Text classification and clustering\n",
    "- Information retrieval and search\n",
    "- Document similarity comparison\n",
    "- Keyword extraction\n",
    "- Feature engineering for NLP tasks\n",
    "- Working with traditional ML models\n",
    "\n",
    "**Avoid when:**\n",
    "- Need semantic understanding (use word embeddings instead)\n",
    "- Word order matters (TF-IDF is bag-of-words)\n",
    "- Working with very short texts\n",
    "- Need context-aware representations (use transformers like BERT)\n",
    "\n",
    "## TF-IDF vs Other Methods\n",
    "\n",
    "| Method | Captures | Order | Semantics | Use Case |\n",
    "|--------|----------|-------|-----------|----------|\n",
    "| TF-IDF | Word importance | No | No | Traditional ML, search |\n",
    "| Word2Vec | Word context | No | Yes | Semantic similarity |\n",
    "| BERT | Contextual meaning | Yes | Yes | Modern NLP tasks |\n",
    "| Count Vectorizer | Word frequency | No | No | Simple baseline |\n",
    "\n",
    "## Key sklearn Methods\n",
    "\n",
    "```python\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform\n",
    "tfidf = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Get feature names (vocabulary)\n",
    "features = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Get IDF values\n",
    "idf_values = vectorizer.idf_\n",
    "\n",
    "# Transform new documents\n",
    "new_tfidf = vectorizer.transform(new_documents)\n",
    "\n",
    "# Get vocabulary dictionary\n",
    "vocab = vectorizer.vocabulary_\n",
    "```\n",
    "\n",
    "## Complete Example: Text Classification Pipeline\n",
    "\n",
    "```python\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Sample dataset\n",
    "texts = [\n",
    "    \"Great product, highly recommend\",\n",
    "    \"Terrible quality, waste of money\",\n",
    "    \"Amazing service and fast delivery\",\n",
    "    \"Poor customer support, disappointed\",\n",
    "    \"Excellent value for money\",\n",
    "    \"Do not buy, completely broken\"\n",
    "]\n",
    "labels = [1, 0, 1, 0, 1, 0]  # 1=positive, 0=negative\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    texts, labels, test_size=0.33, random_state=42\n",
    ")\n",
    "\n",
    "# Vectorize with TF-IDF\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Train model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Test on new text\n",
    "new_text = [\"This product is fantastic\"]\n",
    "new_tfidf = vectorizer.transform(new_text)\n",
    "prediction = model.predict(new_tfidf)\n",
    "print(f\"\\nNew text prediction: {prediction[0]} (1=positive, 0=negative)\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c345afe5",
   "metadata": {},
   "source": [
    "# Manual TF-IDF Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69573083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDF Scores: {'dog': 0.4054651081081644, 'cat': 0.4054651081081644}\n",
      "\n",
      "TF-IDF Scores:\n",
      "Document 0: {'cat': 0.2027325540540822, 'dog': 0.2027325540540822}\n",
      "Document 1: {'dog': 0.4054651081081644}\n",
      "Document 2: {'cat': 0.4054651081081644}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "def calculate_tfidf_manual(documents):\n",
    "    \"\"\"\n",
    "    Manual TF-IDF calculation for understanding\n",
    "    \"\"\"\n",
    "    # Step 1: Calculate TF for each document\n",
    "    tf_scores = []\n",
    "    for doc in documents:\n",
    "        words = doc.lower().split()\n",
    "        word_count = Counter(words)\n",
    "        total_words = len(words)\n",
    "        tf = {word: count/total_words for word, count in word_count.items()}\n",
    "        tf_scores.append(tf)\n",
    "    \n",
    "    # Step 2: Calculate IDF\n",
    "    all_words = set(word for doc in documents for word in doc.lower().split())\n",
    "    num_docs = len(documents)\n",
    "    idf_scores = {}\n",
    "    \n",
    "    for word in all_words:\n",
    "        docs_with_word = sum(1 for doc in documents if word in doc.lower())\n",
    "        idf_scores[word] = math.log(num_docs / docs_with_word)\n",
    "    \n",
    "    # Step 3: Calculate TF-IDF\n",
    "    tfidf_scores = []\n",
    "    for tf in tf_scores:\n",
    "        tfidf = {word: tf_val * idf_scores[word] for word, tf_val in tf.items()}\n",
    "        tfidf_scores.append(tfidf)\n",
    "    \n",
    "    return tfidf_scores, idf_scores\n",
    "\n",
    "# Test\n",
    "docs = [\"cat dog\", \"dog dog\", \"cat\"]\n",
    "tfidf, idf = calculate_tfidf_manual(docs)\n",
    "\n",
    "print(\"IDF Scores:\", idf)\n",
    "print(\"\\nTF-IDF Scores:\")\n",
    "for i, doc_tfidf in enumerate(tfidf):\n",
    "    print(f\"Document {i}: {doc_tfidf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5d4e36",
   "metadata": {},
   "source": [
    "# Quick Implementation with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2375b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['awesome' 'deep' 'enjoy' 'is' 'learning' 'love' 'machine']\n",
      "\n",
      "TF-IDF Matrix:\n",
      "[[0.         0.         0.         0.         0.42544054 0.72033345\n",
      "  0.54783215]\n",
      " [0.5844829  0.         0.         0.5844829  0.34520502 0.\n",
      "  0.44451431]\n",
      " [0.         0.65249088 0.65249088 0.         0.38537163 0.\n",
      "  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Sample documents\n",
    "documents = [\n",
    "    \"I love machine learning\",\n",
    "    \"Machine learning is awesome\",\n",
    "    \"I enjoy deep learning\"\n",
    "]\n",
    "\n",
    "# Create TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform documents\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "# View feature names (words)\n",
    "print(\"Features:\", vectorizer.get_feature_names_out())\n",
    "print()\n",
    "print(\"TF-IDF Matrix:\")\n",
    "print(tfidf_matrix.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2cbfd0",
   "metadata": {},
   "source": [
    "\n",
    "## Understanding the Example\n",
    "\n",
    "**Document 1**: \"I love machine learning\"\n",
    "- \"learning\" appears in all docs → lower TF-IDF (0.4472)\n",
    "- \"love\" and \"machine\" are more distinctive → higher TF-IDF (0.6316)\n",
    "\n",
    "**Document 2**: \"Machine learning is awesome\"\n",
    "- \"awesome\" only appears here → high TF-IDF (0.6316)\n",
    "- \"learning\" appears everywhere → lower TF-IDF (0.4472)\n",
    "\n",
    "**Document 3**: \"I enjoy deep learning\"\n",
    "- \"deep\" and \"enjoy\" only appear here → high TF-IDF (0.6316)\n",
    "- \"learning\" appears everywhere → lower TF-IDF (0.4472)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf21bfbe",
   "metadata": {},
   "source": [
    "# Basic Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3b51fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        and       are       cat      cats       dog      dogs   enemies  \\\n",
      "0  0.000000  0.000000  0.427554  0.000000  0.000000  0.000000  0.000000   \n",
      "1  0.000000  0.000000  0.000000  0.000000  0.427554  0.000000  0.000000   \n",
      "2  0.447214  0.447214  0.000000  0.447214  0.000000  0.447214  0.447214   \n",
      "\n",
      "        log       mat        on       sat       the  \n",
      "0  0.000000  0.427554  0.325166  0.325166  0.650331  \n",
      "1  0.427554  0.000000  0.325166  0.325166  0.650331  \n",
      "2  0.000000  0.000000  0.000000  0.000000  0.000000  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Documents\n",
    "docs = [\n",
    "    \"The cat sat on the mat\",\n",
    "    \"The dog sat on the log\",\n",
    "    \"Cats and dogs are enemies\"\n",
    "]\n",
    "\n",
    "# Create and fit vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf = vectorizer.fit_transform(docs)\n",
    "\n",
    "# View results\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(\n",
    "    tfidf.toarray(),\n",
    "    columns=vectorizer.get_feature_names_out()\n",
    ")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e60574f",
   "metadata": {},
   "source": [
    "# Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90a7f4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Sample data\n",
    "texts = [\n",
    "    \"I love this movie, it's amazing\",\n",
    "    \"Terrible film, waste of time\",\n",
    "    \"Great acting and story\",\n",
    "    \"Boring and poorly made\"\n",
    "]\n",
    "labels = [1, 0, 1, 0]  # 1=positive, 0=negative\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    texts, labels, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "# Vectorize text\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Train classifier\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict\n",
    "predictions = classifier.predict(X_test_tfidf)\n",
    "print(\"Predictions:\", predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12381358",
   "metadata": {},
   "source": [
    "# Find Similar Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b359befd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents similar to 'Python is a programming language':\n",
      "  Doc 1: 0.6016 - 'Java is also a programming language'\n",
      "  Doc 2: 0.2071 - 'Machine learning uses Python'\n",
      "  Doc 3: 0.0000 - 'I love eating pizza'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Documents\n",
    "documents = [\n",
    "    \"Python is a programming language\",\n",
    "    \"Java is also a programming language\",\n",
    "    \"Machine learning uses Python\",\n",
    "    \"I love eating pizza\"\n",
    "]\n",
    "\n",
    "# Vectorize\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Calculate similarity\n",
    "similarity = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "# Find most similar documents to document 0\n",
    "doc_idx = 0\n",
    "similarities = similarity[doc_idx]\n",
    "similar_docs = sorted(\n",
    "    enumerate(similarities), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True\n",
    ")[1:]  # Exclude itself\n",
    "\n",
    "print(f\"Documents similar to '{documents[doc_idx]}':\")\n",
    "for idx, score in similar_docs:\n",
    "    print(f\"  Doc {idx}: {score:.4f} - '{documents[idx]}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7734f828",
   "metadata": {},
   "source": [
    "# Keyword Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c7498dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Keywords:\n",
      "  learning: 0.5898\n",
      "  machine: 0.4423\n",
      "  is: 0.2949\n",
      "  of: 0.2949\n",
      "  field: 0.1474\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "# A single long document\n",
    "document = [\n",
    "    \"Machine learning is a field of artificial intelligence. \"\n",
    "    \"Machine learning algorithms build models based on sample data. \"\n",
    "    \"Deep learning is part of machine learning methods.\"\n",
    "]\n",
    "\n",
    "# Vectorize\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf = vectorizer.fit_transform(document)\n",
    "\n",
    "# Get feature names and scores\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "scores = tfidf.toarray()[0]\n",
    "\n",
    "# Get top keywords\n",
    "top_n = 5\n",
    "top_indices = np.argsort(scores)[::-1][:top_n]\n",
    "\n",
    "print(\"Top Keywords:\")\n",
    "for idx in top_indices:\n",
    "    print(f\"  {feature_names[idx]}: {scores[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673debb9",
   "metadata": {},
   "source": [
    "# Remove Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cef5c1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without stop words:\n",
      "['another' 'document' 'is' 'sample' 'this']\n",
      "\n",
      "With stop words removed:\n",
      "['document' 'sample']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "documents = [\n",
    "    \"This is a sample document\",\n",
    "    \"This document is another sample\"\n",
    "]\n",
    "\n",
    "# Without stop words removal\n",
    "vectorizer_default = TfidfVectorizer()\n",
    "tfidf_default = vectorizer_default.fit_transform(documents)\n",
    "print(\"Without stop words:\")\n",
    "print(vectorizer_default.get_feature_names_out())\n",
    "\n",
    "# With stop words removal\n",
    "vectorizer_no_stop = TfidfVectorizer(stop_words='english')\n",
    "tfidf_no_stop = vectorizer_no_stop.fit_transform(documents)\n",
    "print(\"\\nWith stop words removed:\")\n",
    "print(vectorizer_no_stop.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54bfd75",
   "metadata": {},
   "source": [
    "# Verifying TF-IDF Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d94c1b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['cat' 'dog']\n",
      "\n",
      "TF-IDF Matrix:\n",
      "[[0.93219169 0.361965  ]\n",
      " [0.         1.        ]\n",
      " [0.93219169 0.361965  ]]\n",
      "\n",
      "Document 0 L2 norm: 1.0000\n",
      "\n",
      "Document 1 L2 norm: 1.0000\n",
      "\n",
      "Document 2 L2 norm: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "documents = [\n",
    "    \"cat dog cat\",\n",
    "    \"dog dog dog\",\n",
    "    \"cat cat dog\"\n",
    "]\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "print(\"Features:\", vectorizer.get_feature_names_out())\n",
    "print(\"\\nTF-IDF Matrix:\")\n",
    "print(tfidf_matrix.toarray())\n",
    "\n",
    "# Check: Each document vector should have L2 norm = 1 (by default)\n",
    "for i, doc_vector in enumerate(tfidf_matrix.toarray()):\n",
    "    norm = np.linalg.norm(doc_vector)\n",
    "    print(f\"\\nDocument {i} L2 norm: {norm:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
